**Acumos AI** 
---------------
**SBB Description:** Acumos AI is a platform and open source framework that makes it easy to build, share, and deploy AI apps. Acumos standardizes the infrastructure stack and components required to run an out-of-the-box general AI environment.
Acumos is a platform which enhances the development, training and deployment of AI models. Its purpose is to scale up the introduction of AI-based software across a wide range of industrial and commercial problems in order to reach a critical mass of applications. In this way, Acumos will drive toward a data-centric process for producing software based upon machine learning as the central paradigm. The platform seeks to empower data scientists to publish more adaptive AI models and shield them from the task of custom development of fully integrated solutions. Ideally, software developers will use Acumos to change the process of software development from a code-writing and editing exercise into a classroom-like code training process in which models will be trained and graded on their ability to successfully analyze datasets that they are fed. Then, the best model can be selected for the job and integrated into a complete application.
Acumos is part of the LF Deep Learning Foundation, an umbrella organization within The Linux Foundation that supports and sustains open source innovation in artificial intelligence, machine learning, and deep learning while striving to make these critical new technologies available to developers and data scientists everywhere.

**SBB License:** Apache License 2.0

**Core Technology:** Java

**Project URL:** https://www.acumos.org/

**Source Location:** https://gerrit.acumos.org/r/#/admin/projects/





**AllenNLP** 
--------------
**SBB Description:** An open-source NLP research library, built on PyTorch. AllenNLP is a NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks. AllenNLP makes it easy to design and evaluate new deep learning models for nearly any NLP problem, along with the infrastructure to easily run them in the cloud or on your laptop.

AllenNLP was designed with the following principles:

Hyper-modular and lightweight. Use the parts which you like seamlessly with PyTorch.
Extensively tested and easy to extend. Test coverage is above 90% and the example models provide a template for contributions.
Take padding and masking seriously, making it easy to implement correct models without the pain.
Experiment friendly. Run reproducible experiments from a json specification with comprehensive logging.

**SBB License:** Apache License 2.0

**Core Technology:** Python

**Project URL:** http://allennlp.org/

**Source Location:** https://github.com/allenai/allennlp





**Apache MXNet** 
------------------
**SBB Description:** Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Scala, Go, Javascript and more.
All major GPU and CPU vendors support this project, but also the real giants like Amazon, Microsoft, Wolfram and a number of very respected universities. So watch this project or play with it to see if it fits your use case.
Apache MXNet (incubating) is a deep learning framework designed for both efficiency and flexibility. It allows you to mix symbolic and imperative programming to maximize efficiency and productivity. At its core, MXNet contains a dynamic dependency scheduler that automatically parallelizes both symbolic and imperative operations on the fly. A graph optimization layer on top of that makes symbolic execution fast and memory efficient. MXNet is portable and lightweight, scaling effectively to multiple GPUs and multiple machines.
MXNet is also more than a deep learning project. It is also a collection of blue prints and guidelines for building deep learning systems, and interesting insights of DL systems for hackers.
Gluon is the high-level interface for MXNet. It is more intuitive and easier to use than the lower level interface. Gluon supports dynamic (define-by-run) graphs with JIT-compilation to achieve both flexibility and efficiency. The perfect starters documentation with a great crash course on deep learning can be found here: http://gluon.mxnet.io/

**SBB License:** Apache License 2.0

**Core Technology:** 

**Project URL:** http://mxnet.incubator.apache.org/

**Source Location:** https://github.com/apache/incubator-mxnet





**Apache Spark MLlib** 
------------------------
**SBB Description:** Apache Spark MLlib. MLlib is Apache Spark&#8217;s scalable machine learning library.
Apache Spark is a OSS platform for large-scale data processing. The Spark engine is written in Scala and is well suited for applications that reuse a working set of data across multiple parallel operations. It’s designed to work as a standalone cluster or as part of Hadoop YARN cluster. It can access data from sources such as HDFS, Cassandra or Amazon S3. MLlib can be seen as a core Spark&#8217;s APIs and interoperates with NumPy in Python and R libraries. And Spark is very fast!
MLlib library contains many algorithms and utilities, e.g.:

Classification: logistic regression, naive Bayes,&#8230;
Regression: generalized linear regression, survival regression,&#8230;
Decision trees, random forests, and gradient-boosted trees
Recommendation: alternating least squares (ALS)
Clustering: K-means, Gaussian mixtures (GMMs),&#8230;
Topic modeling: latent Dirichlet allocation (LDA)
Frequent itemsets, association rules, and sequential pattern mining

**SBB License:** Apache License 2.0

**Core Technology:** Java

**Project URL:** https://spark.apache.org/mllib/

**Source Location:** https://github.com/apache/spark





**BigDL** 
-----------
**SBB Description:** BigDL is a distributed deep learning library for Apache Spark; with BigDL, users can write their deep learning applications as standard Spark programs, which can directly run on top of existing Spark or Hadoop clusters.

Rich deep learning support. Modeled after Torch, BigDL provides comprehensive support for deep learning, including numeric computing (via Tensor) and high level neural networks; in addition, users can load pre-trained Caffe or Torch or Keras models into Spark programs using BigDL.
Extremely high performance. To achieve high performance, BigDL uses Intel MKL and multi-threaded programming in each Spark task. Consequently, it is orders of magnitude faster than out-of-box open source Caffe, Torch or TensorFlow on a single-node Xeon (i.e., comparable with mainstream GPU).
Efficiently scale-out. BigDL can efficiently scale out to perform data analytics at &#8220;Big Data scale&#8221;, by leveraging Apache Spark (a lightning fast distributed data processing framework), as well as efficient implementations of synchronous SGD and all-reduce communications on Spark.

**SBB License:** Apache License 2.0

**Core Technology:** Java

**Project URL:** https://bigdl-project.github.io/master/

**Source Location:** https://github.com/intel-analytics/BigDL





**DeepDetect** 
----------------
**SBB Description:** DeepDetect implements support for supervised and unsupervised deep learning of images, text and other data, with focus on simplicity and ease of use, test and connection into existing applications. It supports classification, object detection, segmentation, regression, autoencoders and more.
It has Python and other client libraries.
Deep Detect has also a REST API for Deep Learning with:

JSON communication format
Pre-trained models
Neural architecture templates
Python, Java, C# clients
Output templating

&#160;

**SBB License:** MIT License

**Core Technology:** C++

**Project URL:** https://deepdetect.com

**Source Location:** https://github.com/beniz/deepdetect





**Deeplearn.js** 
------------------
**SBB Description:** Deeplearn.js is an open-source library that brings performant machine learning building blocks to the web, allowing you to train neural networks in a browser or run pre-trained models in inference mode. And since Google is behind this project, a lot of eyes are targeted on this software. Deeplearn.js is an open source hardware accelerated implementation of deep learning APIs in the browser. So there is no need to download or install anything.
Deeplearn.js was originally developed by the Google Brain PAIR team to build powerful interactive machine learning tools for the browser.

**SBB License:** Apache License 2.0

**Core Technology:** Javascript

**Project URL:** https://deeplearnjs.org/

**Source Location:** https://github.com/PAIR-code/deeplearnjs





**Deeplearning4j** 
--------------------
**SBB Description:** Deep Learning for Java, Scala &#38; Clojure on Hadoop &#38; Spark With GPUs.
Eclipse Deeplearning4J is an distributed neural net library written in Java and Scala.
Eclipse Deeplearning4j a commercial-grade, open-source, distributed deep-learning library written for Java and Scala. DL4J is designed to be used in business environments on distributed GPUs and CPUs.
Deeplearning4J integrates with Hadoop and Spark and runs on several backends that enable use of CPUs and GPUs. The aim of this project is to create a plug-and-play solution that is more convention than configuration, and which allows for fast prototyping. This project is created by Skymind who delivers support and offers also the option for machine learning models to be hosted with Skymind&#8217;s model server on a cloud environment

**SBB License:** Apache License 2.0

**Core Technology:** Java

**Project URL:** https://deeplearning4j.org

**Source Location:** https://github.com/deeplearning4j/deeplearning4j





**Detectron** 
---------------
**SBB Description:** Detectron is Facebook AI Research&#8217;s software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework.
The goal of Detectron is to provide a high-quality, high-performance codebase for object detection research. It is designed to be flexible in order to support rapid implementation and evaluation of novel research.
A number of Facebook teams use this platform to train custom models for a variety of applications including augmented reality and community integrity. Once trained, these models can be deployed in the cloud and on mobile devices, powered by the highly efficient Caffe2 runtime.

**SBB License:** Apache License 2.0

**Core Technology:** Python

**Project URL:** https://github.com/facebookresearch/Detectron

**Source Location:** https://github.com/facebookresearch/Detectron





**Fabrik** 
------------
**SBB Description:** Fabrik is an online collaborative platform to build, visualize and train deep learning models via a simple drag-and-drop interface. It allows researchers to collaboratively develop and debug models using a web GUI that supports importing, editing and exporting networks written in widely popular frameworks like Caffe, Keras, and TensorFlow.

**SBB License:** GNU General Public License (GPL) 3.0

**Core Technology:** Javascript, Python

**Project URL:** http://fabrik.cloudcv.org/

**Source Location:** https://github.com/Cloud-CV/Fabrik





**Gensim** 
------------
**SBB Description:** Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing (NLP) and information retrieval (IR) community.
&#160;

**SBB License:** MIT License

**Core Technology:** Python

**Project URL:** https://github.com/RaRe-Technologies/gensim

**Source Location:** https://github.com/RaRe-Technologies/gensim





**Keras** 
-----------
**SBB Description:** Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.
Use Keras if you need a deep learning library that:

Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).
Supports both convolutional networks and recurrent networks, as well as combinations of the two.
Runs seamlessly on CPU and GPU.

**SBB License:** MIT License

**Core Technology:** Python

**Project URL:** https://keras.io/

**Source Location:** https://github.com/keras-team/keras





**Luminoth** 
--------------
**SBB Description:** Luminoth is an open source toolkit for computer vision. Currently, we support object detection and image classification, but we are aiming for much more. It is built in Python, using TensorFlow and Sonnet.
&#160;

**SBB License:** BSD License 2.0 (3-clause, New or Revised) License

**Core Technology:** Python

**Project URL:** https://luminoth.ai

**Source Location:** https://github.com/tryolabs/luminoth





**MacroBase** 
---------------
**SBB Description:** MacroBase is a new analytic monitoring engine designed to prioritize human attention in large-scale datasets and data streams. Unlike a traditional analytics engine, MacroBase is specialized for one task: finding and explaining unusual or interesting trends in data. Developed by Stanford Future Data Systems
Documentation can be found at: https://macrobase.stanford.edu/docs/

**SBB License:** Apache License 2.0

**Core Technology:** Java

**Project URL:** https://macrobase.stanford.edu/

**Source Location:** https://github.com/stanford-futuredata/macrobase/tree/v1.0





**ONNX** 
----------
**SBB Description:** ONNX provides an open source format for AI models. It defines an extensible computation graph model, as well as definitions of built-in operators and standard data types. Initially we focus on the capabilities needed for inferencing (evaluation).
Caffe2, PyTorch, Microsoft Cognitive Toolkit, Apache MXNet and other tools are developing ONNX support. Enabling interoperability between different frameworks and streamlining the path from research to production will increase the speed of innovation in the AI community. We are an early stage and we invite the community to submit feedback and help us further evolve ONNX.
Companies behind ONNX are AWS, Facebook and Microsoft Corporation and more.

**SBB License:** MIT License

**Core Technology:** Python

**Project URL:** http://onnx.ai/

**Source Location:** https://github.com/onnx/onnx





**OpenCV: Open Source Computer Vision Library** 
-------------------------------------------------
**SBB Description:** OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. Being a BSD-licensed product, OpenCV makes it easy for businesses to utilize and modify the code.
The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc.

**SBB License:** BSD License 2.0 (3-clause, New or Revised) License

**Core Technology:** C

**Project URL:** https://opencv.org/

**Source Location:** https://github.com/opencv/opencv





**OpenML** 
------------
**SBB Description:** OpenML is an on-line machine learning platform for sharing and organizing data, machine learning algorithms and experiments. It claims to be designed to create a frictionless, networked ecosystem, so that you can readily integrate into your existing processes/code/environments. It also allows people from all over the world to collaborate and build directly on each other’s latest ideas, data and results, irrespective of the tools and infrastructure they happen to use. So nice ideas to build an open science movement. The people behind OpemML are mostly (data)scientist. So using this product for real world business use cases will take some extra effort.
Altrhough OpenML is exposed as an foundation based on openness, a quick inspection learned that the OpenML platform  is not as open as you want. Also the OSS software is not created to be run on premise. So be aware when doing large (time) investments into this OpenML platform.

**SBB License:** BSD License 2.0 (3-clause, New or Revised) License

**Core Technology:** Java

**Project URL:** https://openml.org

**Source Location:** https://github.com/openml/OpenML





**Orange** 
------------
**SBB Description:** Orange is a comprehensive, component-based software suite for machine learning and data mining, developed at Bioinformatics Laboratory.
Orange is available by default on Anaconda Navigator dashboard. Orange is a component-based data mining software. It includes a range of data visualization, exploration, preprocessing and modeling techniques. It can be used through a nice and intuitive user interface or, for more advanced users, as a module for the Python programming language.
One of the nice features is the option for visual programming. Can you do visual interactive data exploration for rapid qualitative analysis with clean visualizations. The graphic user interface allows you to focus on exploratory data analysis instead of coding, while clever defaults make fast prototyping of a data analysis workflow extremely easy.
&#160;
&#160;

**SBB License:** GNU General Public License (GPL) 3.0

**Core Technology:** 

**Project URL:** https://orange.biolab.si/

**Source Location:** https://github.com/biolab/orange3





**Pattern** 
-------------
**SBB Description:** Pattern is a web mining module for Python. It has tools for:

Data Mining: web services (Google, Twitter, Wikipedia), web crawler, HTML DOM parser
Natural Language Processing: part-of-speech taggers, n-gram search, sentiment analysis, WordNet
Machine Learning: vector space model, clustering, classification (KNN, SVM, Perceptron)
Network Analysis: graph centrality and visualization.

**SBB License:** BSD License 2.0 (3-clause, New or Revised) License

**Core Technology:** Python

**Project URL:** https://www.clips.uantwerpen.be/pages/pattern

**Source Location:** https://github.com/clips/pattern





**Plait** 
-----------
**SBB Description:** plait.py is a program for generating fake data from composable yaml templates.
With plait it is easy to model fake data that has an interesting shape. Currently, many fake data generators model their data as a collection of IID variables; with plait.py we can stitch together those variables into a more coherent model.
Example uses for plait.py are:

generating mock application data in test environments
validating the usefulness of statistical techniques
creating synthetic datasets for performance tuning databases

**SBB License:** MIT License

**Core Technology:** Python

**Project URL:** https://github.com/plaitpy/plaitpy

**Source Location:** https://github.com/plaitpy/plaitpy





**Pyro** 
----------
**SBB Description:** Deep universal probabilistic programming with Python and PyTorch. Pyro is in an alpha release. It is developed and used by Uber AI Labs.

&#160;

**SBB License:** GNU General Public License (GPL) 2.0

**Core Technology:** Python

**Project URL:** http://pyro.ai/

**Source Location:** https://github.com/uber/pyro





**PyTorch** 
-------------
**SBB Description:** PyTorch is:

a deep learning framework that puts Python first.
 a research-focused framework.
Python package that provides two high-level features:

Pytorch uses tensor computation (like NumPy) with strong GPU acceleration. It can use deep neural networks built on a tape-based autograd system.
You can reuse your favorite Python packages such as NumPy, SciPy and Cython to extend PyTorch when needed.
Note: PyTorch is still in an early-release beta phase (status January 2018). PyTorch was released as OSS by Google January 2017.

**SBB License:** MIT License

**Core Technology:** Python

**Project URL:** http://pytorch.org/

**Source Location:** https://github.com/pytorch/pytorch





**Ray** 
---------
**SBB Description:** Ray is a flexible, high-performance distributed execution framework for AI applications. Ray is currently under heavy development. But Ray has already a good start, with good documentation (http://ray.readthedocs.io/en/latest/index.html) and a tutorial. Also Ray is backed by scientific researchers and published papers.
Ray comes with libraries that accelerate deep learning and reinforcement learning development:

Ray Tune: Hyperparameter Optimization Framework
Ray RLlib: A Scalable Reinforcement Learning Library

**SBB License:** Apache License 2.0

**Core Technology:** Python

**Project URL:** https://ray-project.github.io/

**Source Location:** https://github.com/ray-project/ray





**Scikit-learn** 
------------------
**SBB Description:** scikit-learn is a Python module for machine learning.
Simple and efficient tools for data mining and data analysis

Accessible to everybody, and reusable in various contexts
Built on NumPy, SciPy, and matplotlib

**SBB License:** BSD License 2.0 (3-clause, New or Revised) License

**Core Technology:** Python

**Project URL:** http://scikit-learn.org

**Source Location:** https://github.com/scikit-learn/scikit-learn





**Snorkel** 
-------------
**SBB Description:** Snorkel is a system for rapidly creating, modeling, and managing training data, currently focused on accelerating the development of structured or &#8220;dark&#8221; data extraction applications for domains in which large labeled training sets are not available or easy to obtain.

**SBB License:** Apache License 2.0

**Core Technology:** Python

**Project URL:** https://hazyresearch.github.io/snorkel/

**Source Location:** https://github.com/HazyResearch/snorkel





**Tensorflow** 
----------------
**SBB Description:** TensorFlow is an Open Source Software Library for Machine Intelligence. TensorFlow is by far the most used and popular ML open source project. And since the first initial release was only just in November 2015 it is expected that the impact of this OSS package will expand even more.
TensorFlow™ is an open source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API. TensorFlow was originally developed by researchers and engineers working on the Google Brain Team within Google&#8217;s Machine Intelligence research organization for the purposes of conducting machine learning and deep neural networks research, but the system is general enough to be applicable in a wide variety of other domains as well.
TensorFlow comes with a tool called TensorBoard which you can use to get some insight into what is happening. TensorBoard is a suite of web applications for inspecting and understanding your TensorFlow runs and graphs.

**SBB License:** Apache License 2.0

**Core Technology:** C

**Project URL:** https://www.tensorflow.org/

**Source Location:** https://github.com/tensorflow/tensorflow





**Theano** 
------------
**SBB Description:** Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation.
Note: After almost ten years of development the company behind Theano has stopped development and support(Q4-2017). But this library has been an innovation driver for many other OSS ML packages!
Since a lot of ML libraries and packages use Theano you should check (as always) the health of your ML stack.

**SBB License:** MIT License

**Core Technology:** Python

**Project URL:** http://www.deeplearning.net/

**Source Location:** https://github.com/Theano/Theano





**Thinc** 
-----------
**SBB Description:** Thinc is the machine learning library powering spaCy. It features a battle-tested linear model designed for large sparse learning problems, and a flexible neural network model under development for spaCy v2.0.
Thinc is a practical toolkit for implementing models that follow the &#8220;Embed, encode, attend, predict&#8221; architecture. It&#8217;s designed to be easy to install, efficient for CPU usage and optimised for NLP and deep learning with text – in particular, hierarchically structured input and variable-length sequences.

**SBB License:** GNU General Public License (GPL) 2.0

**Core Technology:** Python

**Project URL:** https://explosion.ai/

**Source Location:** https://github.com/explosion/thinc





**Turi** 
----------
**SBB Description:** Turi Create simplifies the development of custom machine learning models. Turi is OSS machine learning from Apple.
Turi Create simplifies the development of custom machine learning models. You don&#8217;t have to be a machine learning expert to add recommendations, object detection, image classification, image similarity or activity classification to your app.

**SBB License:** BSD License 2.0 (3-clause, New or Revised) License

**Core Technology:** Python

**Project URL:** https://github.com/apple/turicreate

**Source Location:** https://github.com/apple/turicreate





**VisualDL** 
--------------
**SBB Description:** VisualDL is an open-source cross-framework web dashboard that richly visualizes the performance and data flowing through your neural network training. VisualDL is a deep learning visualization tool that can help design deep learning jobs. It includes features such as scalar, parameter distribution, model structure and image visualization.

**SBB License:** Apache License 2.0

**Core Technology:** C++

**Project URL:** http://visualdl.paddlepaddle.org/

**Source Location:** https://github.com/PaddlePaddle/VisualDL





End of SBB list <br>